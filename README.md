# OtusLinux_Homework_12.
Что сделано:
- написан playbook для первоначальной настройки хоста после инсталляции, который:
    - устанавливает нужные инструменты для анализа и траблшутинга (роль monitoring)
    - устанавливает параметры ядра, параметры сети и параметры памяти под работу в качестве сервера (роль tuning)
    - устанавливает nginx из предыдущей домашней работы (роль web)
Как запустить:
- из директории HW12-Monitoring запустить "vagrant up" 

# OtusLinux_Homework_11.
Что сделано:
- подготовлен стенд на Vagrant с одним сервером. На этом сервере используя Ansible развернут nginx со следующими условиями:
    - использован модуль yum
    - конфигурационные файлы взяты из шаблона jinja2 с перемененными
    - после установки nginx переводится в режиме enabled в systemd
    - использован notify для старта nginx после установки
    - сайт слушает на нестандартном порту - 8080, для этого использованы переменные в Ansible
- подготовлен второй стенд на Vagrant, на котором сделано все тоже самое использованием Ansible роли

Как запуситить:
- Для случая применения плейбука:
    - запустить vagrant из директории Ansible
    - из этой же директрии запустить "ansible-playbook playbooks/nginx.yml"
- Для случая применения роли:
    - запустить vagrant из директории Ansible_Role
    - из этой же директрии запустить "ansible-playbook playbooks/web.yml"

# OtusLinux_Homework_9.
Что сделано:
- Реализованы 2 конкурирующих процесса по IO, которые запускаются с разными ionice (директория ionice).
  Для этого:
    - созданы 2 скрипта (script1.sh и script2.sh), которые с помощью утилиты dd генерируют файлы first и second соответственно. Выходными параметрами является время выполнения скрипта
    - создан скрипт-стартер (start.sh), который запускает вышеописанные скрипты параллельно с разными ionice (-c1 для script1.sh и -c3 для script2.sh), а результат исполнения скриптов записывает в файл-лог (io-race.log)
  Результат:
    - Результат можно увидеть в логе io_race.log. Скрипты запускались под root.
- Реализованы 2 конкурирующих процесса по CPU, которые запускаются с разными nice (директория nice).
  Для этого:
    - созданы 2 скрипта (cpu_script1.sh и cpu_script2.sh), которые с помощью утилиты time подсчитывают время вычисления md5sum. Подсчитанное время записывается в лог файл (cpu_race.log)
    - создан скрипт-стартер (cpu_start.sh), который сперва создает временный файл, необходимый для посчета md5sum. Затем скрипт запускает вышеописанные скрипты параллельно с разными nice (19 для script1.sh и -19 для script2.sh). Временный файл удаляется после выполнения.
  Результат:
    - Результат можно увидеть в логе cpu_race.log. Скрипты запускались под root.

# OtusLinux_Homework_8.
Что сделано:
- Создан свой RPM пакет 
  Для этого:
    - Подготавливаем систему для сборки своего пакета, доустанавливая нужные пакеты
    - Загружаем исходники пакета NGINX и устанавливаем скачанный пакет
    - Загружаем исходники openssl и разархивируем их в директорию /usr/lib
    - Ставим все зависимости nginx, указанные в nginx.spec
    - Изменяем spec файл (меняем --with-debug на usr/lib/openssl-1.1.1a)
    - Собираем свой пакет и устанавливаем его для проверки.
- Создан свой репозиторий, в котором размещен ранее собранный RPM
  Для этого:
    - Для прозрачности настроиваем в NGINX доступ к листингу каталога добавив "autoindex on" после строчки "index  ndex.html index.htm" и запускаем nginx
    - Создаем директорию "repo" в каталоге для статики NGINX и копируем в неё собранный RPM 
    - Загружаем Percona-Server в директорию создаваемого репозитория
    - Инициализируем репозиторий и добавляем созданный репозиторий в /etc/yum.repos.d
    - Для проверки устанавливаем percona-server из локального репозитория
Как проверить:
- Запустить vagrant, который должен подхватить Vagrantfile, в котором прописан provision.sh, отвечающий за разворачивание лабы

# OtusLinux_Homework_7.
Что сделано:
- Настроен запрет всем пользователям, кроме группы admin логин в выходные и праздничные дни
  Для этого:
    - изменен сценарий login (/etc/pam.d/login): добавлена работа модуля "pam_time.so" и проверка на находждения в группе администраторов
    - добавлен файл с временными рамками time.conf
- Выданы конкретному пользователю права рута 
  Для этого:
    - скопировали полный "набор прав" root в файл caps (для получения набора зашли под рутом и запустили "getpcaps $$"
    - дополнили сценарий su модулем "pam_cap.so"

# OtusLinux_Homework_6.
Что сделано:
- Написан сервис (servicekey), который раз в 30 секунд мониторит лог на предмет наличия ключевого слова. Файл и слово задаваются в /etc/sysconfig. Для развертывания данного сервиса используется скрипт provision.sh, логика работы описана в комментариях
- Из epel установлен spawn-fcgi и переписан init-скрипт на unit-файл. Имя сервиса называться также. Конфиги и скрипт развертывания (provision.sh) лежат в директории spawn-fcgi. Т.к. задача является учебной, то обвязка spawn-fcgi с nginx и с приложением выходит за рамки данного ДЗ
- Дополнен unit-файл apache httpd возможностью запустить несколько инстансов сервера с разными конфигами. Для проверки достаточно запустить provision.sh, находящийся в httpd. 
  
# OtusLinux_Homework_5.
Что сделано:
- Написать скрипт для крона, который раз в час (настраивается в кроне) присылает на заданную почту (прописывается в скрипте)
    - X IP адресов (с наибольшим кол-вом запросов) с указанием кол-ва запросов c момента последнего запуска скрипта
    - Y запрашиваемых адресов (с наибольшим кол-вом запросов) с указанием кол-ва запросов c момента последнего запуска скрипта
    - все ошибки c момента последнего запуска
    - список всех кодов возврата с указанием их кол-ва с момента последнего запуска
    - в письме прописан обрабатываемый временной диапазон (указано время с которого начинается обработка)
    - Реализована защита от мультизапуска

Как проверить:
- В скрипте необходимо прописать пути до файлов логов (т.к. задача учебная и логов nginx у меня нет, то тренировался "на кошках" - файлах - примерах. По умолчанию пути прописаны до этих файлов в директории размещения скрипта)
- Для приведенных примеров логов нужно убрать заглушку в скрипте (#Заглушка для проверки на старых логах). Для проверки на "боевых" логах заглушку нужно убрать.

Пример:
- Пример вывода работы скрипта можно увидеть в приложенном файле output

# OtusLinux_Homework_4.
Что сделано:
- Осуществлен вход в систему без пароля несколькими способами:
    - Первый способ:
        Останавливаем загрузчик, в менюшке нажимаем 'e' для редактирования загрузчика
        Добавляем в параметры запуска ядра (строчка linux16) команду rd.break enforcing=0, нажимаем ctrl+x для перезагрузки
        Меняем пароль от root:

        mount -o remount,rw /sysroot
        chroot /sysroot
        passwd
        touch /.autorelabel
        mount -o remount,ro /
        exit
        exit

    - Второй способ:
        Останавливаем загрузчик, в менюшке нажимаем 'e' для редактирования загрузчика
        Добавляем в параметры запуска ядра (строчка linux16) команду init=/sysroot/bin/sh (подменив init процесс), нажимаем ctrl+x для перезагрузки
        Меняем пароль от root

        mount -o remount,rw /
        passwd
        touch /.autorelabel
        mount -o remount,ro /
        reboot
- Переименован VG. Лог работ приложен в work_part1.log, пруф на положительный результат в начале work_part2.log
- Добавлен модуль в initrd.  Лог работ приложен в work_part2.log. Скрипты заброшены с хост-машины в виртуальную командами:
    vagrant scp ./module-setup.sh otuslinux:/home/vagrant
    vagrant scp ./test.sh otuslinux:/home/vagrant


# OtusLinux_Homework_3.
Что сделано:
- Уменьшен том под / до 8G
- Выделен отдельный том под /home
- Выделен отдельный том под /var, том сделан в mirror
- /home сделан с условием снятия снапшотов. Работа проверена на примере восстановления со снапшота после удаления части файлов, заранее сгенерированных, перед снятием снапшота.
- Прописано монтирование в fstab.


# OtusLinux_Homework_2.
Что сделано:
- С помощью Vagrant поднята виртуальная машина c 6 дисками (дополнен конфигурационный файл)
- Собран RAID10, в mdadm.conf прописан его конфиг для загрузки при старте системы (теоретически этого можно не делать, информация о рейде записывается в образ начальной загрузки, однако, наличие файла mdadm.conf делает загрузку предсказуемой) 
- Создан GPT раздел и 5 партиций
- Выполнено задание со *. В конфиг Vagrant дописаны: доустановка пакета e2fsprogs.x86_64 (для создания партиций ext4), команды создания raid10, прописывания конфига рейда в mdadm, создания раздела и партиций, их форматирования и монтирования.


# OtusLinux_Homework_1.
Что сделано:
- С помощью Vagrant поднята виртуальная машина 
- На виртуальную машину с сайта https://www.kernel.org/ скачано ядро linux-3.16.61
- Собрали ядро. Согласно условиям ДЗ вытянут файл результирующей конфигурации и список модулей